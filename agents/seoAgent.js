const Anthropic = require('@anthropic-ai/sdk');
const perplexityService = require('../services/perplexityService');
const { getClaudeModel, getModelDisplayName, shouldUsePerplexity, shouldUseDeepSeek } = require('../utils/modelHelper');
const deepseekService = require('../services/deepseekService');

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

async function analyzeSEO(client_name, brief, options = {}) {
  const { model: modelSelection = 'deepseek', no_fallback = false } = options;
  const modelsUsed = [];
  let webResearch = null;

  // If Perplexity is selected, use it for the full analysis
  if (modelSelection === 'perplexity' && perplexityService.isAvailable()) {
    return await analyzeWithPerplexity(client_name, brief, modelsUsed);
  }

  // Optionally use Perplexity for current SEO trends and competitor analysis (when using other models)
  if (shouldUsePerplexity(modelSelection)) {
    try {
      console.log('ğŸ” Gathering current SEO trends via Perplexity...');
      const researchResult = await perplexityService.research(
        `Current SEO trends and best practices for: ${brief}. Focus on: latest algorithm updates, effective strategies, and keyword trends.`,
        {
          searchRecency: 'week',
          maxTokens: 800,
          systemPrompt: 'You are an SEO expert. Provide current, actionable SEO insights based on latest search engine updates and trends.'
        }
      );
      webResearch = researchResult.content;
      console.log('âœ… Web research completed');
    } catch (error) {
      console.warn('âš ï¸ Web research unavailable, using Claude-only analysis:', error.message);
    }
  }

  // Use DeepSeek if selected and available
  if (shouldUseDeepSeek(modelSelection)) {
    return await analyzeWithDeepSeek(client_name, brief, webResearch, modelSelection, no_fallback, modelsUsed);
  }

  // Build prompt with optional web research context
  const contextNote = webResearch
    ? `\n\n**æœ€æ–° SEO è³‡è¨Š (ä¾†è‡ªç¶²çµ¡ç ”ç©¶)**:\n${webResearch}\n\nè«‹çµåˆä»¥ä¸Šæœ€æ–°è³‡è¨Šå’Œä½ çš„å°ˆæ¥­çŸ¥è­˜ä¾†æä¾›å»ºè­°ã€‚`
    : '';

  const claudeModel = getClaudeModel(modelSelection);

  const response = await client.messages.create({
    model: claudeModel,
    max_tokens: modelSelection === 'sonnet' ? 2000 : 1000,
    messages: [
      {
        role: 'user',
        content: `ä½ æ˜¯ä¸€å€‹ SEO å°ˆå®¶ã€‚è«‹ç‚ºä»¥ä¸‹é …ç›®æä¾› SEO ç­–ç•¥ã€‚

**å®¢æˆ·**: ${client_name}
**ç°¡å ±**: ${brief}${contextNote}

è«‹è¿”å› JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸éœ€è¦å…¶ä»–æ–‡æœ¬ï¼‰:
{
  "target_keywords": ["é—œéµè©1", "é—œéµè©2"],
  "content_strategy": "å…§å®¹ç­–ç•¥æè¿°",
  "technical_seo": ["æŠ€è¡“1", "æŠ€è¡“2"],
  "backlink_opportunities": ["æ©Ÿæœƒ1", "æ©Ÿæœƒ2"],
  "timeline_months": 6,
  "current_trends": ["è¶¨å‹¢1", "è¶¨å‹¢2"]
}`,
      },
    ],
  });

  // Track Claude usage
  modelsUsed.push({
    model: getModelDisplayName(modelSelection),
    model_id: claudeModel,
    usage: {
      input_tokens: response.usage?.input_tokens || 0,
      output_tokens: response.usage?.output_tokens || 0,
      total_tokens: (response.usage?.input_tokens || 0) + (response.usage?.output_tokens || 0)
    }
  });

  const text = response.content[0].text;
  try {
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : { raw: text };

    return {
      ...analysis,
      _meta: {
        models_used: modelsUsed,
        enhanced_with_web_research: !!webResearch
      }
    };
  } catch {
    return {
      raw: text,
      _meta: {
        models_used: modelsUsed,
        enhanced_with_web_research: !!webResearch
      }
    };
  }
}

async function analyzeWithDeepSeek(client_name, brief, webResearch, modelSelection, no_fallback = false, modelsUsed = []) {
  const contextNote = webResearch
    ? `\n\n**æœ€æ–° SEO è³‡è¨Š (ä¾†è‡ªç¶²çµ¡ç ”ç©¶)**:\n${webResearch}\n\nè«‹çµåˆä»¥ä¸Šæœ€æ–°è³‡è¨Šå’Œä½ çš„å°ˆæ¥­çŸ¥è­˜ä¾†æä¾›å»ºè­°ã€‚`
    : '';

  const systemPrompt = 'ä½ æ˜¯ä¸€å€‹ SEO å°ˆå®¶ã€‚è«‹ç‚ºä»¥ä¸‹é …ç›®æä¾› SEO ç­–ç•¥ã€‚';
  const userPrompt = `**å®¢æˆ·**: ${client_name}
**ç°¡å ±**: ${brief}${contextNote}

è«‹è¿”å› JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸éœ€è¦å…¶ä»–æ–‡æœ¬ï¼‰:
{
  "target_keywords": ["é—œéµè©1", "é—œéµè©2"],
  "content_strategy": "å…§å®¹ç­–ç•¥æè¿°",
  "technical_seo": ["æŠ€è¡“1", "æŠ€è¡“2"],
  "backlink_opportunities": ["æ©Ÿæœƒ1", "æ©Ÿæœƒ2"],
  "timeline_months": 6,
  "current_trends": ["è¶¨å‹¢1", "è¶¨å‹¢2"]
}`;

  try {
    const result = await deepseekService.analyze(systemPrompt, userPrompt, {
      maxTokens: 1500,
    });

    // Track DeepSeek usage
    modelsUsed.push({
      model: getModelDisplayName(modelSelection),
      model_id: 'deepseek-chat',
      usage: result.usage || {}
    });

    const text = result.content;

    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : { raw: text };

      return {
        ...analysis,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: !!webResearch
        }
      };
    } catch {
      return {
        raw: text,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: !!webResearch
        }
      };
    }
  } catch (error) {
    if (no_fallback) {
      throw new Error(`DeepSeek API error: ${error.message}`);
    }
    console.error('DeepSeek error, falling back to Claude Haiku:', error.message);
    return await analyzeSEO(client_name, brief, { model: 'haiku', no_fallback: false });
  }
}

async function analyzeWithPerplexity(client_name, brief, modelsUsed = []) {
  const jsonSchema = `{
  "target_keywords": ["é—œéµè©1", "é—œéµè©2"],
  "content_strategy": "å…§å®¹ç­–ç•¥æè¿°",
  "technical_seo": ["æŠ€è¡“å»ºè­°1", "æŠ€è¡“å»ºè­°2"],
  "backlink_opportunities": ["æ©Ÿæœƒ1", "æ©Ÿæœƒ2"],
  "timeline_months": æ•¸å­—
}`;

  const systemPrompt = `ä½ æ˜¯ä¸€å€‹ SEO å°ˆå®¶ã€‚è«‹ç‚ºä»¥ä¸‹é …ç›®æä¾› SEO ç­–ç•¥ï¼Œçµåˆ2026å¹´æœ€æ–°çš„æœç´¢å¼•æ“ç®—æ³•æ›´æ–°å’Œè¶¨å‹¢ã€‚
è«‹è¿”å› JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸éœ€è¦å…¶ä»–æ–‡æœ¬ï¼‰ã€‚`;

  const userPrompt = `**å®¢æˆ·**: ${client_name}
**ç°¡å ±**: ${brief}

è«‹æä¾›å®Œæ•´çš„ SEO ç­–ç•¥ï¼ŒåŒ…æ‹¬ç›®æ¨™é—œéµè©ã€å…§å®¹ç­–ç•¥ã€æŠ€è¡“ SEO å»ºè­°ã€å¤–éˆæ©Ÿæœƒå’Œå¯¦æ–½æ™‚é–“è¡¨ã€‚

è«‹è¿”å›ä»¥ä¸‹ JSON æ ¼å¼:
${jsonSchema}`;

  try {
    const result = await perplexityService.research(
      userPrompt,
      {
        systemPrompt,
        maxTokens: 2000,
        searchRecency: 'week',
        temperature: 0.3
      }
    );

    // Track Perplexity usage
    modelsUsed.push({
      model: getModelDisplayName('perplexity'),
      model_id: 'sonar-pro',
      usage: result.usage || {}
    });

    const text = result.content;

    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : { raw: text };

      return {
        ...analysis,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: true,
          sources: result.citations || []
        }
      };
    } catch {
      return {
        raw: text,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: true,
          sources: result.citations || []
        }
      };
    }
  } catch (error) {
    throw new Error(`Perplexity API error: ${error.message}`);
  }
}

module.exports = { analyzeSEO };
