const Anthropic = require('@anthropic-ai/sdk');
const perplexityService = require('../services/perplexityService');
const { getClaudeModel, getModelDisplayName, shouldUsePerplexity, shouldUseDeepSeek } = require('../utils/modelHelper');
const deepseekService = require('../services/deepseekService');

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

async function analyzeSocial(client_name, brief, options = {}) {
  const { model: modelSelection = 'deepseek', no_fallback = false } = options;
  const modelsUsed = [];
  let webResearch = null;

  // If Perplexity is selected, use it for the full analysis
  if (modelSelection === 'perplexity' && perplexityService.isAvailable()) {
    return await analyzeWithPerplexity(client_name, brief, modelsUsed);
  }

  // Optionally use Perplexity for current social media trends (when using other models)
  if (shouldUsePerplexity(modelSelection)) {
    try {
      console.log('ğŸ” Gathering current social media trends via Perplexity...');
      const researchResult = await perplexityService.research(
        `Current social media trends, viral content strategies, and platform algorithm updates for: ${brief}. Focus on what's working now in 2026.`,
        {
          searchRecency: 'week',
          maxTokens: 800,
          systemPrompt: 'You are a social media strategist. Provide current, actionable insights about social media trends, viral content, and platform updates.'
        }
      );
      webResearch = researchResult.content;
      console.log('âœ… Web research completed');
    } catch (error) {
      console.warn('âš ï¸ Web research unavailable, using Claude-only analysis:', error.message);
    }
  }

  // Use DeepSeek if selected and available
  if (shouldUseDeepSeek(modelSelection)) {
    return await analyzeWithDeepSeek(client_name, brief, webResearch, modelSelection, no_fallback, modelsUsed);
  }

  // Build prompt with optional web research context
  const contextNote = webResearch
    ? `\n\n**æœ€æ–°ç¤¾äº¤åª’é«”è¶¨å‹¢ (ä¾†è‡ªç¶²çµ¡ç ”ç©¶)**:\n${webResearch}\n\nè«‹çµåˆä»¥ä¸Šæœ€æ–°è¶¨å‹¢å’Œä½ çš„å°ˆæ¥­çŸ¥è­˜ä¾†æä¾›å»ºè­°ã€‚`
    : '';

  const claudeModel = getClaudeModel(modelSelection);

  const response = await client.messages.create({
    model: claudeModel,
    max_tokens: modelSelection === 'sonnet' ? 2000 : 1000,
    messages: [
      {
        role: 'user',
        content: `ä½ æ˜¯ä¸€å€‹ç¤¾äº¤åª’é«”ç­–ç•¥å¸«ã€‚è«‹ç‚ºä»¥ä¸‹é …ç›®æä¾›ç¤¾äº¤åª’é«”ç­–ç•¥ã€‚

**å®¢æˆ·**: ${client_name}
**ç°¡å ±**: ${brief}${contextNote}

è«‹è¿”å› JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸éœ€è¦å…¶ä»–æ–‡æœ¬ï¼‰:
{
  "primary_platforms": ["å¹³å°1", "å¹³å°2"],
  "content_pillars": ["æ”¯æŸ±1", "æ”¯æŸ±2"],
  "posting_frequency": "æ¯å‘¨æ¬¡æ•¸",
  "engagement_strategy": "äº’å‹•ç­–ç•¥æè¿°",
  "hashtag_strategy": ["hashtag1", "hashtag2"],
  "trending_formats": ["æ ¼å¼1", "æ ¼å¼2"]
}`,
      },
    ],
  });

  // Track Claude usage
  modelsUsed.push({
    model: getModelDisplayName(modelSelection),
    model_id: claudeModel,
    usage: {
      input_tokens: response.usage?.input_tokens || 0,
      output_tokens: response.usage?.output_tokens || 0,
      total_tokens: (response.usage?.input_tokens || 0) + (response.usage?.output_tokens || 0)
    }
  });

  const text = response.content[0].text;
  try {
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : { raw: text };

    return {
      ...analysis,
      _meta: {
        models_used: modelsUsed,
        enhanced_with_web_research: !!webResearch
      }
    };
  } catch {
    return {
      raw: text,
      _meta: {
        models_used: modelsUsed,
        enhanced_with_web_research: !!webResearch
      }
    };
  }
}

async function analyzeWithDeepSeek(client_name, brief, webResearch, modelSelection, no_fallback = false, modelsUsed = []) {
  const contextNote = webResearch
    ? `\n\n**æœ€æ–°ç¤¾äº¤åª’é«”è¶¨å‹¢ (ä¾†è‡ªç¶²çµ¡ç ”ç©¶)**:\n${webResearch}\n\nè«‹çµåˆä»¥ä¸Šæœ€æ–°è¶¨å‹¢å’Œä½ çš„å°ˆæ¥­çŸ¥è­˜ä¾†æä¾›å»ºè­°ã€‚`
    : '';

  const systemPrompt = 'ä½ æ˜¯ä¸€å€‹ç¤¾äº¤åª’é«”ç­–ç•¥å¸«ã€‚è«‹ç‚ºä»¥ä¸‹é …ç›®æä¾›ç¤¾äº¤åª’é«”ç­–ç•¥ã€‚';
  const userPrompt = `**å®¢æˆ·**: ${client_name}
**ç°¡å ±**: ${brief}${contextNote}

è«‹è¿”å› JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸éœ€è¦å…¶ä»–æ–‡æœ¬ï¼‰:
{
  "primary_platforms": ["å¹³å°1", "å¹³å°2"],
  "content_pillars": ["æ”¯æŸ±1", "æ”¯æŸ±2"],
  "posting_frequency": "æ¯å‘¨æ¬¡æ•¸",
  "engagement_strategy": "äº’å‹•ç­–ç•¥æè¿°",
  "hashtag_strategy": ["hashtag1", "hashtag2"],
  "trending_formats": ["æ ¼å¼1", "æ ¼å¼2"]
}`;

  try {
    const result = await deepseekService.analyze(systemPrompt, userPrompt, {
      maxTokens: 1500,
    });

    // Track DeepSeek usage
    modelsUsed.push({
      model: getModelDisplayName(modelSelection),
      model_id: 'deepseek-chat',
      usage: result.usage || {}
    });

    const text = result.content;

    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : { raw: text };

      return {
        ...analysis,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: !!webResearch
        }
      };
    } catch {
      return {
        raw: text,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: !!webResearch
        }
      };
    }
  } catch (error) {
    if (no_fallback) {
      throw new Error(`DeepSeek API error: ${error.message}`);
    }
    console.error('DeepSeek error, falling back to Claude Haiku:', error.message);
    return await analyzeSocial(client_name, brief, { model: 'haiku', no_fallback: false });
  }
}

async function analyzeWithPerplexity(client_name, brief, modelsUsed = []) {
  const jsonSchema = `{
  "primary_platforms": ["å¹³å°1", "å¹³å°2"],
  "content_pillars": ["æ”¯æŸ±1", "æ”¯æŸ±2"],
  "posting_frequency": "æ¯å‘¨æ¬¡æ•¸",
  "engagement_strategy": "äº’å‹•ç­–ç•¥æè¿°",
  "hashtag_strategy": ["hashtag1", "hashtag2"],
  "trending_formats": ["æ ¼å¼1", "æ ¼å¼2"]
}`;

  const systemPrompt = `ä½ æ˜¯ä¸€å€‹ç¤¾äº¤åª’é«”ç­–ç•¥å¸«ã€‚è«‹ç‚ºä»¥ä¸‹é …ç›®æä¾›ç¤¾äº¤åª’é«”ç­–ç•¥ï¼Œçµåˆ2026å¹´æœ€æ–°çš„ç¤¾äº¤åª’é«”è¶¨å‹¢å’Œå¹³å°æ›´æ–°ã€‚
è«‹è¿”å› JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸éœ€è¦å…¶ä»–æ–‡æœ¬ï¼‰ã€‚`;

  const userPrompt = `**å®¢æˆ·**: ${client_name}
**ç°¡å ±**: ${brief}

è«‹æä¾›å®Œæ•´çš„ç¤¾äº¤åª’é«”ç­–ç•¥ï¼ŒåŒ…æ‹¬å¹³å°é¸æ“‡ã€å…§å®¹æ”¯æŸ±ã€ç™¼å¸ƒé »ç‡ã€äº’å‹•ç­–ç•¥ã€æ¨™ç±¤ç­–ç•¥å’Œæµè¡Œæ ¼å¼ã€‚

è«‹è¿”å›ä»¥ä¸‹ JSON æ ¼å¼:
${jsonSchema}`;

  try {
    const result = await perplexityService.research(
      userPrompt,
      {
        systemPrompt,
        maxTokens: 2000,
        searchRecency: 'week',
        temperature: 0.3
      }
    );

    // Track Perplexity usage
    modelsUsed.push({
      model: getModelDisplayName('perplexity'),
      model_id: 'sonar-pro',
      usage: result.usage || {}
    });

    const text = result.content;

    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      const analysis = jsonMatch ? JSON.parse(jsonMatch[0]) : { raw: text };

      return {
        ...analysis,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: true,
          sources: result.citations || []
        }
      };
    } catch {
      return {
        raw: text,
        _meta: {
          models_used: modelsUsed,
          enhanced_with_web_research: true,
          sources: result.citations || []
        }
      };
    }
  } catch (error) {
    throw new Error(`Perplexity API error: ${error.message}`);
  }
}

module.exports = { analyzeSocial };
