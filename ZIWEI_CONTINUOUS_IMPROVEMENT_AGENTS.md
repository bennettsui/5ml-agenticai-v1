# Ziwei Knowledge - Continuous Improvement Agent Architecture

**Based on:** 5ML Platform's 7-Layer Architecture
**Objective:** Continuously expand, validate, and improve Ziwei knowledge database
**Cost Model:** Prioritized by value/cost ratio with automated stopping conditions

---

## 7-Layer Architecture Integration

```
Layer 7: Interface Layer (UI/UX)
         â†“
Layer 6: Orchestration Layer (Agent Coordinator)
         â†“ (directs)
Layer 5: Workflow Agents (Knowledge Building Agents)
         â”œâ”€ æœç´¢Agent (Search Agent)
         â”œâ”€ é©—è­‰Agent (Validation Agent)
         â”œâ”€ åˆ†æAgent (Analysis Agent)
         â””â”€ æ“è­·è€…Agent (Devil's Advocate Agent)
         â†“
Layer 4: Knowledge Layer (Ziwei Database)
         â”œâ”€ Stars Database
         â”œâ”€ Palace Meanings
         â”œâ”€ Rules Database
         â””â”€ Accuracy Metrics
         â†“
Layer 3: Service Layer (Calculations)
         â”œâ”€ Chart Calculator
         â”œâ”€ Rule Evaluator
         â””â”€ Luck Cycle Engine
         â†“
Layer 2: Data Layer (Storage)
         â”œâ”€ PostgreSQL
         â”œâ”€ Vector Store (embeddings)
         â””â”€ Source Registry
         â†“
Layer 1: Infrastructure Layer (Deployment)
```

---

## Agentic Workflow for Continuous Knowledge Building

### ğŸ¯ Overall Flow

```
Orchestration Agent (Layer 6)
    â†“ Evaluates knowledge gaps
    â”œâ”€â†’ Knowledge Gap Detector (identifies gaps)
    â”œâ”€â†’ Priority Scorer (ranks by value/cost)
    â”œâ”€â†’ Search Agent (Layer 5) - Searches online
    â”œâ”€â†’ Validation Agent (Layer 5) - Cross-validates
    â”œâ”€â†’ Devil's Advocate (Layer 5) - Critiques findings
    â””â”€â†’ Integration Agent (Layer 5) - Updates KB

    â†“ Continuous Loop (Daily/Weekly/Monthly)
    â””â”€â†’ Metrics Engine â†’ Confidence Scores
        â†“
        Triggers re-evaluation if scores drop
```

---

## Individual Agents & Specifications

### 1. **Orchestration Agent (Layer 6) - Coordinator**

**Role:** Directs all knowledge-building activities

**Responsibilities:**
- Monitor knowledge gap priorities
- Allocate token budgets to workflow agents
- Coordinate search, validation, and critique
- Decide when to integrate new knowledge
- Track cost vs. benefit metrics
- Stop unnecessary agents when target confidence reached

**Decision Rules:**
```
IF knowledge_gap.confidence < 0.8 AND cost_budget_remaining > 0:
    TRIGGER â†’ Search Agent
    WAIT â†’ Results + Devil's Advocate critique
    IF devil_advocate.confidence >= 0.7:
        TRIGGER â†’ Integration Agent
    ELSE:
        REFINE search parameters
        RETRY up to 3 times
ELSE:
    SKIP (too expensive or sufficiently confident)
```

**Cost/Benefit Calculation:**
```
priority_score = (gap_severity Ã— value_weight) / (estimated_cost Ã— cost_weight)

gap_severity: 1-5 (CRITICAL=5, HIGH=4, MEDIUM=3, LOW=2, TRIVIAL=1)
value_weight: Impact on system (0.0-1.0)
estimated_cost: API calls, tokens, compute time
cost_weight: Budget sensitivity (0.5-2.0 based on budget)
```

**Token Budget:**
- Daily: 50,000 tokens for continuous improvement
- Weekly: Additional 100,000 for deep research
- Monthly: 200,000 for comprehensive validation
- Unused budget carries over (up to 500K max)

---

### 2. **Search Agent (Layer 5) - Knowledge Discovery**

**Role:** Find new knowledge from online sources

**Trigger Conditions:**
- Knowledge gap identified (confidence < 0.8)
- New source discovered
- User feedback indicates missing knowledge
- Quarterly scheduled search

**Search Strategy:**
```
Phase 1: Authoritative Sources (Priority 1)
â”œâ”€ Zhihu ç‹äº­ä¹‹ articles
â”œâ”€ Ziwei.asia official content
â”œâ”€ Academic databases (if accessible)
â””â”€ Cost: 5,000-10,000 tokens

Phase 2: Specialized Resources (Priority 2)
â”œâ”€ Educational platforms
â”œâ”€ Practitioner blogs
â”œâ”€ Forum discussions
â””â”€ Cost: 3,000-5,000 tokens

Phase 3: Supporting References (Priority 3)
â”œâ”€ Wikipedia-style resources
â”œâ”€ YouTube transcripts
â”œâ”€ Community discussions
â””â”€ Cost: 1,000-3,000 tokens
```

**Output:**
- Structured findings
- Source credibility scores
- Confidence levels
- Conflicting interpretations noted
- Ready for Devil's Advocate critique

**Stopping Conditions:**
- Reached target confidence (0.85+)
- Covered all Priority 1 sources
- Token budget exhausted
- 3 consecutive searches with no new info
- Time limit (2 hours max per search)

---

### 3. **Validation Agent (Layer 5) - Cross-Validation**

**Role:** Verify knowledge against multiple sources

**Validation Process:**
```
For each new knowledge item:

1. Multi-source validation
   â”œâ”€ Check against existing database
   â”œâ”€ Compare with other sources
   â”œâ”€ Validate mathematical consistency
   â””â”€ Check real-world applicability

2. Conflict detection
   â”œâ”€ Different sources contradict?
   â”œâ”€ Identify primary vs secondary sources
   â”œâ”€ Document all variations
   â””â”€ Score confidence by source priority

3. Consistency checks
   â”œâ”€ Does it fit system logic?
   â”œâ”€ Conflicts with established rules?
   â”œâ”€ Edge cases handled?
   â””â”€ Complete vs partial information?

4. Score assignment
   â”œâ”€ Source credibility (0.0-1.0)
   â”œâ”€ Consensus across sources (0.0-1.0)
   â”œâ”€ Internal consistency (0.0-1.0)
   â””â”€ Final confidence = average
```

**Output:**
- Validation report
- Confidence scores
- Source attribution
- Identified conflicts (for Devil's Advocate)
- Ready for integration or rejection

**Stopping Conditions:**
- Confidence threshold met (0.80+)
- All available sources checked
- Clear consensus reached
- Irreconcilable conflicts documented

---

### 4. **Devil's Advocate Agent (Layer 5) - Quality Control**

**Role:** Critique findings and challenge assumptions

**Mission:** Ensure accuracy, identify gaps, recommend improvements

**Scope & Constraints:**
```
Engagement Scope:
â”œâ”€ ALWAYS active for: Confidence < 0.7 or conflicting sources
â”œâ”€ Optional for: Confidence 0.7-0.85
â”œâ”€ Skip for: Confidence 0.85+ (unless user requests)
â””â”€ Max engagement: 5 minutes per item (can extend if critical)

Length Constraints:
â”œâ”€ Critical issues: Up to 10 critique points
â”œâ”€ High priority: Up to 5 critique points
â”œâ”€ Medium priority: Up to 3 critique points
â””â”€ Low priority: Up to 1 critique point

Cost Constraints:
â”œâ”€ Max tokens per critique: 2,000
â”œâ”€ If exceeds â†’ Summarize & escalate to Orchestration
â””â”€ Can skip if daily token budget exhausted
```

**Devil's Advocate Process:**

**Phase 1: Challenge Assumptions**
```
Questions to ask:
1. "Is this based on ç‹äº­ä¹‹ (authoritative source)?"
   â†’ If NO: Risk flagged, source credibility questioned

2. "How many sources confirm this interpretation?"
   â†’ If only 1: Single-source risk

3. "Does this contradict established rules?"
   â†’ If YES: Conflict documented, requires resolution

4. "Is there alternative interpretation?"
   â†’ If YES: Documented as competing theory

5. "What's the empirical basis?"
   â†’ If unknown: Confidence score reduced
```

**Phase 2: Identify Knowledge Gaps**
```
For each new knowledge item, ask:
- "What assumptions underlie this?"
- "What could prove this wrong?"
- "What's NOT being said?"
- "Are there edge cases?"
- "Does this apply universally?"
```

**Phase 3: Recommend Improvements**
```
Priority recommendations:
1. CRITICAL: Must address before integration
2. HIGH: Address before production use
3. MEDIUM: Address in next phase
4. LOW: Consider for future improvement
```

**Phase 4: Confidence Adjustment**
```
Base confidence from Validation Agent
â†“
Devil's Advocate applies modifiers:
â”œâ”€ Source quality issues: -0.05 to -0.25
â”œâ”€ Unresolved conflicts: -0.10 to -0.30
â”œâ”€ Missing empirical data: -0.05 to -0.15
â”œâ”€ Edge cases not handled: -0.05 to -0.10
â””â”€ Strong theoretical backing: +0.05 to +0.10
â†“
Final confidence score (0.0-1.0)
```

**Critique Output Example:**
```json
{
  "knowledge_item": "Ziwei in å‘½å®® = Imperial authority",
  "source_confidence": 0.85,
  "devil_advocate_critique": {
    "challenges": [
      {
        "level": "HIGH",
        "issue": "Only ç‹äº­ä¹‹ as authoritative source; needs cross-validation",
        "risk": "Single-source bias"
      },
      {
        "level": "MEDIUM",
        "issue": "Modern context differences - imperial authority no longer relevant in 2026",
        "recommendation": "Reframe as 'leadership authority' for contemporary use"
      },
      {
        "level": "LOW",
        "issue": "No documented empirical validation",
        "recommendation": "Track accuracy metrics over time"
      }
    ],
    "adjusted_confidence": 0.75,
    "recommendation": "INTEGRATE with modern interpretation update",
    "follow_up_research": ["Collect real chart examples", "Track prediction accuracy"]
  }
}
```

**Stopping Conditions:**
- Time limit reached (5 minutes default)
- All major concerns addressed
- Contradiction cannot be resolved without escalation
- Token budget for this item exhausted
- Sufficient confidence achieved (0.80+)

---

### 5. **Integration Agent (Layer 5) - Database Update**

**Role:** Add validated knowledge to live database

**Integration Process:**
```
1. Pre-integration validation
   â”œâ”€ Final confidence check (0.75+ required)
   â”œâ”€ Source attribution confirmed
   â”œâ”€ No conflicting entries
   â””â”€ Schema validation passed

2. Database update
   â”œâ”€ Insert/update records
   â”œâ”€ Version control (timestamp + source)
   â”œâ”€ Confidence score assignment
   â””â”€ Source attribution

3. Post-integration
   â”œâ”€ Cache invalidation
   â”œâ”€ API endpoint refresh
   â”œâ”€ Notification to UI layer
   â””â”€ Metrics update

4. Verification
   â”œâ”€ Query newly integrated data
   â”œâ”€ Validate consistency
   â”œâ”€ Test in interpretation engine
   â””â”€ Log integration event
```

**Stopping Condition:**
- Successful integration OR rollback on error

---

## Workflow Examples

### Example 1: Star Meanings Discovery (High Priority)

```
Orchestration Agent:
â”œâ”€ Detects: "104 stars missing complete palace meanings (Gap #2)"
â”œâ”€ Calculates: priority = (CRITICAL Ã— 1.0) / (8000 tokens Ã— 0.8) = 0.156 (HIGH)
â”œâ”€ Budget check: Has 45,000 tokens available âœ“
â””â”€ TRIGGERS: Search Agent

Search Agent:
â”œâ”€ Phase 1: Queries Ziwei.asia (official source)
â”‚  â””â”€ Finds: 14 main stars Ã— 12 palaces = 168 combinations
â”œâ”€ Phase 2: Queries Gagan Sarkaria database
â”‚  â””â”€ Finds: All 104 stars reference list
â”œâ”€ Phase 3: Queries Fusang Vision star dictionary
â”‚  â””â”€ Finds: Detailed palace meanings for 14 stars
â””â”€ Returns: 3,500 findings â†’ 12,000 tokens used

Validation Agent:
â”œâ”€ Checks: 168 combinations against sources
â”œâ”€ Conflict resolution: Prioritize ç‹äº­ä¹‹ > Official > Educational
â”œâ”€ Assigns confidence: avg 0.82
â””â”€ Reports: Ready for Devil's Advocate

Devil's Advocate:
â”œâ”€ Challenge: "All from current sources?"
â”‚  â””â”€ Issue: MEDIUM - No ç‹äº­ä¹‹ original text verification
â”œâ”€ Recommend: "Add official ç‹äº­ä¹‹ source check"
â”œâ”€ Adjust confidence: 0.82 â†’ 0.76
â””â”€ Decision: INTEGRATE with high priority follow-up research

Integration Agent:
â”œâ”€ Inserts: 168 star-palace combinations
â”œâ”€ Version tags: "2026-02-18_phase-1-scraping_conf-0.76"
â”œâ”€ Updates: Orchestration Agent priority queue
â””â”€ Result: SUCCESS - Ready for Phase 2

Total tokens used: 12,000
Budget remaining: 33,000
New knowledge: 168 star-palace combinations added
```

### Example 2: Transformation Rules Discovery (Critical)

```
Orchestration Agent:
â”œâ”€ Detects: "Four Transformations incomplete (Gap #7, Confidence 0.25)"
â”œâ”€ Calculates: priority = (CRITICAL Ã— 1.0) / (6000 tokens Ã— 0.8) = 0.208 (CRITICAL)
â”œâ”€ Budget check: 33,000 tokens available âœ“
â””â”€ TRIGGERS: Search Agent

Search Agent:
â”œâ”€ Phase 1: Queries æ˜Ÿæ—å­¸è‹‘ (Four Transformations specialist) PRIMARY SOURCE
â”‚  â””â”€ Finds: Complete å››åŒ– system documentation
â”œâ”€ Phase 2: Queries Vocus transformation guides
â”‚  â””â”€ Finds: Multiple interpretations of each transformation type
â””â”€ Returns: 850 findings â†’ 8,500 tokens used

Validation Agent:
â”œâ”€ Maps: 10 stems Ã— 4 transformation types = 40 base rules
â”œâ”€ Cross-validates: Multiple sources for each rule
â”œâ”€ Checks: Consistency with existing database
â”œâ”€ Assigns: avg confidence 0.88
â””â”€ Reports: High-quality findings, ready for review

Devil's Advocate:
â”œâ”€ Challenge 1: "Is this ç‹äº­ä¹‹ endorsed?"
â”‚  â””â”€ Finding: YES - æ˜Ÿæ—å­¸è‹‘ uses ä¸­å·æ´¾ framework âœ“
â”œâ”€ Challenge 2: "Any conflicting interpretations?"
â”‚  â””â”€ Finding: Minor variations between sources â†’ documented
â”œâ”€ Challenge 3: "Empirical validation?"
â”‚  â””â”€ Issue: MEDIUM - No historical case studies
â”œâ”€ Recommend: "Add empirical tracking post-launch"
â”œâ”€ Adjust confidence: 0.88 â†’ 0.85
â””â”€ Decision: INTEGRATE + FLAG FOR VALIDATION TRACKING

Integration Agent:
â”œâ”€ Inserts: 40 transformation rules
â”œâ”€ Links: To affected stars and palaces
â”œâ”€ Updates: Rule evaluation engine
â””â”€ Result: SUCCESS - å››åŒ– layer now functional

Total tokens used: 8,500
Budget remaining: 24,500
New knowledge: 40 transformation rules
Next phase: Validation tracking setup
```

---

## Cost & Benefit Analysis

### Cost Model

| Agent Activity | Tokens | Frequency | Monthly Cost |
|---|---|---|---|
| Search (Priority 1 sources) | 10,000 | 2/month | 20,000 |
| Search (Priority 2 sources) | 5,000 | 4/month | 20,000 |
| Search (Priority 3 sources) | 2,000 | 8/month | 16,000 |
| Validation runs | 3,000 | 12/month | 36,000 |
| Devil's Advocate reviews | 2,000 | 15/month | 30,000 |
| Integration & updates | 1,000 | 20/month | 20,000 |
| **Monthly total** | | | **142,000 tokens** |

**Cost at $0.01 per 1,000 tokens:** ~$1.42/month (minimal)
**Cost at $0.50 per 1,000 tokens (higher rate):** ~$71/month

---

### Benefit Model (Per Knowledge Item Added)

| Item Type | Knowledge Value | System Impact | User Value |
|---|---|---|---|
| Single star meaning | 1 point | Low | Medium |
| Star-palace combination | 5 points | Medium | Medium |
| Transformation rule | 10 points | High | High |
| Luck cycle algorithm | 50 points | Critical | High |
| Pattern rule | 8 points | High | Medium |
| Accuracy metric | 20 points | Critical | Low |

**Benefits of completing knowledge base:**
- âœ… Serve 100% of user charts accurately
- âœ… Provide å¤§é‹/æµå¹´ predictions (high-value feature)
- âœ… Apply å››åŒ– transformations (essential layer)
- âœ… Reduce error rates by ~60%
- âœ… Enable advanced pattern recognition
- âœ… Support decision-making (career/wealth/relationship)

---

## Continuous Improvement Loop

```
Weekly Loop:
â”œâ”€ Monday: Orchestration evaluates gaps
â”œâ”€ Tuesday: Search Agent runs scheduled searches
â”œâ”€ Wednesday: Validation Agent cross-checks findings
â”œâ”€ Thursday: Devil's Advocate reviews critiques
â”œâ”€ Friday: Integration Agent updates database
â””â”€ Weekend: Metrics analysis & plan next week

Monthly Loop:
â”œâ”€ Week 1-2: Focus on HIGH priority gaps
â”œâ”€ Week 3: Focus on MEDIUM priority gaps
â”œâ”€ Week 4: Validation & accuracy metrics
â””â”€ Summary: Report coverage increase % to user

Quarterly Loop:
â”œâ”€ Deep research on Priority 1 sources (ç‹äº­ä¹‹)
â”œâ”€ Empirical validation against real charts
â”œâ”€ Accuracy metrics compilation
â””â”€ Decision: Adjust priorities based on results

Annual Loop:
â”œâ”€ Complete target knowledge base (95%+)
â”œâ”€ Publish accuracy statistics
â”œâ”€ Update user-facing documentation
â””â”€ Plan next-year improvements
```

---

## Orchestration Agent Decision Rules

### When to Activate Search Agent:
```python
def should_search(gap):
    if gap.confidence < 0.8 and budget_remaining > gap.estimated_cost:
        if gap.severity in ['CRITICAL', 'HIGH']:
            return True  # Activate search
        elif gap.severity == 'MEDIUM' and budget_ratio > 0.05:
            return True  # Activate if good value/cost
    return False
```

### When to Activate Devil's Advocate:
```python
def should_critique(findings):
    if findings.confidence < 0.70:
        return True  # Always critique low confidence
    elif findings.confidence < 0.85 and findings.has_conflicts:
        return True  # Critique if conflicts exist
    elif findings.severity == 'CRITICAL':
        return True  # Always critique critical items
    return False  # Skip for high-confidence items
```

### When to Stop and Integrate:
```python
def should_integrate(validated_knowledge):
    if validated_knowledge.final_confidence >= 0.75:
        return True  # Meet minimum threshold
    if validated_knowledge.sources >= 3 and all_agree:
        return True  # Strong consensus
    if token_budget_exhausted or time_limit_reached:
        return True  # Stop researching
    return False  # Need more validation
```

---

## Addressing User Feedback & Iteration

### Feedback Loop:
```
User asks question â†’ System cannot answer
    â†“
Log as knowledge gap (highest priority)
    â†“
Orchestration Agent evaluates (priority = CRITICAL)
    â†“
Search â†’ Validate â†’ Critique â†’ Integrate
    â†“
Next query has answer
```

### Quality Improvement:
```
Track user satisfaction with interpretations
    â†“
0-1 month: Track predictions accuracy
    â†“
3 months: Compile metrics, identify weak areas
    â†“
6 months: Adjust confidence scores based on real outcomes
    â†“
12 months: Publish accuracy report, plan improvements
```

---

## Summary: Value Proposition

âœ… **Automated knowledge expansion** - No manual research needed
âœ… **Quality control** - Devil's Advocate ensures accuracy
âœ… **Cost-effective** - ~$1-70/month depending on token rates
âœ… **Scalable** - Handles continuous improvement indefinitely
âœ… **Transparent** - Source attribution and confidence scores visible
âœ… **User-focused** - Prioritizes gaps that matter to users
âœ… **Measurable** - Tracks coverage % and accuracy metrics

---

**Document Date:** 2026-02-18
**Next Review:** 2026-02-25 (weekly)
**Target Implementation:** Week 1 of Phase 2 (March 4-18)
